<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Recent Talks and Tutorials</title>
  <meta content="Hans-Georg Beyer" name="author">
  <meta http-equiv="content-type"
 content="text/html; charset=ISO-8859-1">
</head>
<body>
<table style="width: 840px; height: 1215px;" border="0" cellpadding="0"
 cellspacing="0">
  <tbody>
    <tr>
      <td style="background-color: rgb(255, 255, 102);" class="links"
 align="center" valign="top" width="260"> 
          <tr>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td
 style="background-color: rgb(255, 255, 102); text-align: center;"
 class="level1"><a href="index.html" target="_top"><span
 style="font-weight: bold;">Hans-Georg
Beyer</span><br>
            </a></td>
          </tr>
        </tbody>
      </table>
      <table border="0" cellpadding="6" cellspacing="1" width="100%">
        <tbody>
          <tr>
            <td style="background-color: rgb(255, 255, 102);"
 class="level1"><a href="CV.html"><span
 style="text-decoration: underline;"></span></a><a href="CV.html"><img
 alt="" src="arrow.gif"
 style="border: 0px solid ; width: 20px; height: 9px;"></a><a
 href="CV.html">Curriculum
Vitae</a><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><img alt="" src="arrow.gif"
 style="width: 20px; height: 9px;"><a href="HGB-pub.pdf">Publications and
Patents</a><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><a href="downloads.html"><img
 alt="" src="arrow.gif"
 style="border: 0px solid ; width: 20px; height: 9px;"></a><a
 href="downloads.html">Downloads</a><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr align="center">
            <td style="vertical-align: top;"><span
 style="font-weight: bold; color: rgb(0, 0, 238);">Information Sources</span><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><a
 href="ea-glossary/ea-terms-engl.html">Evolutionary Algorithms <br>
Terms and Definitions</a><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;"><a
 href="ea-terminologie/richtlinien.html">Evolution&auml;re Algorithmen <br>
Begriffe, Definitionen und W&ouml;rterbuch</a><br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      </td>
      <td width="10"><br>
      </td>
      <td class="current" valign="top">
      <div style="text-align: left;"> </div>
      <table style="width: 603px; height: 37px;" class="current">
        <tbody>
          <tr>
            <td nowrap="nowrap" valign="bottom" width="100%">
            <h2>Prof.
Dr. rer. nat. habil. Hans-Georg Beyer</h2>
            </td>
          </tr>
        </tbody>
      </table>
      <hr noshade="noshade" size="1">
      <h1 style="text-align: center;">Recent Talks and Tutorials<br>
      </h1>

<h2>1. Evolution Strategies are Not Gradient Followers</h2>
In order to explain the working principles of Evolution Strategies (ESs)
in real-valued search spaces, sometimes the picture of a (stochastic) 
gradient approximating strategy is invoked. There are publications in 
the field of machine learning and evolutionary algorithms where this 
misleading picture is promoted. Therefore, I gave a talk at 
Dagstuhl, <a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19431">
Seminar 19431 (Oct. 20 - 25, 2019),</a>
showing that this picture is not correct: ESs are much more explorative than 
gradient strategies, thus they have a certain chance of not being trapped in the 
next local attractor. The slides of that talk can 
be obtained <a href="downloads/ES-Is-Not-Gradient-Follower.pdf">here.</a><br> 
BTW, even the consideration of ESs as Monte-Carlo approximators of the 
so-called natural gradient does not hold for standard ESs such as the 
Covariance Matrix Adapation ES. A discussion of that topic can be found in my paper 
<a href="New-Papers/ECJ-Bey13-2020-revision.pdf">Convergence Analysis of Evolutionary Algorithms
That are Based on the Paradigm of Information Geometry</a>. While the main 
part of that paper is rather technical, the Introduction and the Conclusions
should be easy to follow.<br>


<h2>2. Design Principles for Matrix Adaptation Evolution Strategies</h2>

In the paper <a href="https://ieeexplore.ieee.org/document/7875115">Simplify Your 
Covariance Matrix Adaptation Evolution Strategy</a> we have shown that one can 
simplify this well-performing ES by removing the covariance matrix totally 
from the CMA-ES without performance degradation. As a result one obtains simpler
Evolution Strategies that allow for further algorithm engineering addressing 
high-dimensional search spaces and constrained optimization problems. 
<a href="downloads/MA-ES-Principles-Tutorial.pdf">Here are tutorial slides</a> 
discussing these topics. <br>
Matlab/Octave code of the basic algorithms can be found at 
<a href="downloads.html">Downloads</a>
      <br>
      <br>
      <br>
last change: 14.07.2020<br>
      </td>
    </tr>
  </tbody>
</table>
</body>
</html>
